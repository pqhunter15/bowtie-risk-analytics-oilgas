import json
import argparse
from pathlib import Path
from typing import Any, Dict, List
import pandas as pd


def _to_json_str(x: Any) -> str:
    """Stable JSON string for nested objects in CSV cells."""
    return json.dumps(x, ensure_ascii=False, sort_keys=True)


def _flatten_dict(
    obj: Dict[str, Any],
    prefix: str,
    sep: str = "__"
) -> Dict[str, Any]:
    """
    Flatten a nested dict into a 1-level dict of columns.
    Lists are kept losslessly as JSON strings.
    Dicts recurse; scalars stay as-is.
    """
    out: Dict[str, Any] = {}

    def rec(cur: Any, key_prefix: str):
        if isinstance(cur, dict):
            for k, v in cur.items():
                rec(v, f"{key_prefix}{sep}{k}" if key_prefix else k)
        elif isinstance(cur, list):
            out[key_prefix] = _to_json_str(cur)
        else:
            out[key_prefix] = cur

    rec(obj, prefix)
    return out


def flatten_incidents_lossless_to_controls_csv(
    input_path: Path,
    output_path: Path,
    keep_raw_json: bool = True
) -> None:
    """
    Reads an aggregated incidents JSON file (list of incident dicts),
    writes a barrier/control-level CSV with lossless preservation of all fields.
    """
    input_path = Path(input_path)
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    incidents = json.loads(input_path.read_text(encoding="utf-8"))
    if not isinstance(incidents, list):
        raise ValueError("Expected input file to be a JSON list of incident objects.")

    rows: List[Dict[str, Any]] = []

    for doc in incidents:
        if not isinstance(doc, dict):
            continue

        bowtie = doc.get("bowtie", {}) or {}
        controls = bowtie.get("controls", []) or []
        if not isinstance(controls, list):
            controls = []

        # Copy incident-level dict, but remove bowtie.controls (controls are emitted per-row)
        incident_copy = dict(doc)
        incident_bowtie = dict(bowtie) if isinstance(bowtie, dict) else {}
        incident_bowtie.pop("controls", None)
        incident_copy["bowtie"] = incident_bowtie

        incident_cols = _flatten_dict(incident_copy, prefix="incident")

        hazards = bowtie.get("hazards", [])
        threats = bowtie.get("threats", [])
        consequences = bowtie.get("consequences", [])

        bowtie_cols = {
            "bowtie__hazards_json": _to_json_str(hazards) if hazards is not None else None,
            "bowtie__threats_json": _to_json_str(threats) if threats is not None else None,
            "bowtie__consequences_json": _to_json_str(consequences) if consequences is not None else None,
        }

        # Optionally emit a row even if no controls exist
        if len(controls) == 0:
            row = {}
            row.update(incident_cols)
            row.update(bowtie_cols)
            row["control__control_id"] = None
            if keep_raw_json:
                row["incident_raw_json"] = _to_json_str(doc)
                row["control_raw_json"] = None
            rows.append(row)
            continue

        for c in controls:
            if not isinstance(c, dict):
                continue

            control_cols = _flatten_dict(c, prefix="control")

            row = {}
            row.update(incident_cols)
            row.update(bowtie_cols)
            row.update(control_cols)

            if keep_raw_json:
                row["incident_raw_json"] = _to_json_str(doc)
                row["control_raw_json"] = _to_json_str(c)

            rows.append(row)

    df = pd.DataFrame(rows)

    preferred_first = [
        "incident__incident_id",
        "control__control_id",
        "control__name",
        "control__side",
        "control__barrier_type",
        "control__line_of_defense",
        "control__performance__barrier_failed",
        "control__human__barrier_failed_human",
        "control__human__linked_pif_ids",
        "bowtie__hazards_json",
        "bowtie__threats_json",
        "bowtie__consequences_json",
    ]
    cols = list(df.columns)
    ordered = [c for c in preferred_first if c in cols] + [c for c in cols if c not in preferred_first]
    df = df[ordered]

    # IMPORTANT: keep utf-8 and no index
    df.to_csv(output_path, index=False, encoding="utf-8")
    print(f"Wrote {len(df)} barrier rows â†’ {output_path}")


def parse_args(default_input: Path, default_output: Path):
    parser = argparse.ArgumentParser(
        description="Flatten aggregated incidents.json to a lossless barrier/control-level CSV"
    )
    parser.add_argument(
        "--input",
        type=Path,
        default=default_input,
        help=f"Input aggregated incidents.json (default: {default_input})"
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=default_output,
        help=f"Output CSV path (default: {default_output})"
    )
    parser.add_argument(
        "--no-raw-json",
        action="store_true",
        help="Do not include incident_raw_json/control_raw_json columns (smaller CSV)"
    )
    return parser.parse_args()


if __name__ == "__main__":
    # ---- Project-relative defaults ----
    BASE_DIR = Path(__file__).resolve().parent
    PROJECT_ROOT = BASE_DIR.parent

    DEFAULT_INPUT = PROJECT_ROOT / "data" / "processed" / "aggregatedjsons" / "filename.json"
    DEFAULT_OUTPUT = PROJECT_ROOT / "data" / "processed" / "flattenedcsvs" / "filename.csv"

    args = parse_args(DEFAULT_INPUT, DEFAULT_OUTPUT)

    input_path = args.input.resolve()
    output_path = args.output.resolve()

    flatten_incidents_lossless_to_controls_csv(
        input_path=input_path,
        output_path=output_path,
        keep_raw_json=not args.no_raw_json
    )
